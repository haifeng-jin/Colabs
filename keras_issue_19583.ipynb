{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6BcFso/gYrcShKqSeIC3W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haifeng-jin/Colabs/blob/main/keras_issue_19583.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras==3.3.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XoPSoicr55VQ",
        "outputId": "d370ec6a-18cf-4ac1-afe1-64906a025df4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras==3.3.2\n",
            "  Using cached keras-3.3.2-py3-none-any.whl (1.1 MB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras==3.3.2) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras==3.3.2) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras==3.3.2) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras==3.3.2) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras==3.3.2) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras==3.3.2) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras==3.3.2) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras==3.3.2) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.3.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras==3.3.2) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras==3.3.2) (0.1.2)\n",
            "Installing collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.2.0\n",
            "    Uninstalling keras-3.2.0:\n",
            "      Successfully uninstalled keras-3.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed keras-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "J_DzmL3K5j0H",
        "outputId": "88f371b9-13cf-4e9b-b25f-98d42aa230bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n",
            "Keras version: 3.3.2\n",
            "Original dataset: <_TensorDataset element_spec=TensorSpec(shape=(1,), dtype=tf.uint8, name=None)>\n",
            "Original dataset items: [<tf.Tensor: shape=(1,), dtype=uint8, numpy=array([1], dtype=uint8)>]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ category_encoding (\u001b[38;5;33mCategoryEncoding\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ category_encoding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CategoryEncoding</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category encoding model input dtype: 'uint8'\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
            "\n",
            "\n",
            "Symbolicly encoded categories using tf.one_hot: <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 1.]], dtype=float32)>\n",
            "Symbolicly encoded categories using keras backend one_hot: <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 1.]], dtype=float32)>\n",
            "CategoryEncoding compute dtype: 'float32'\n",
            "keras.utils.tree.map_structure with converted dtype: <tf.Tensor: shape=(1,), dtype=float32, numpy=array([1.], dtype=float32)>\n",
            "Eagerly encoded categories: <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0., 1.]], dtype=float32)>\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Reproduce automatic casting tf.uint8 to tf.float32 in symbolic execution\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "print(f\"TensorFlow version: {tf.version.VERSION}\")\n",
        "print(f\"Keras version: {keras.version()}\")\n",
        "\n",
        "ds_tensor = tf.constant([1], dtype=tf.uint8)\n",
        "\n",
        "ds = tf.data.Dataset.from_tensors(ds_tensor)\n",
        "print(f\"Original dataset: {repr(ds)}\")\n",
        "print(f\"Original dataset items: {repr(list(ds))}\")\n",
        "\n",
        "category_encoding = keras.layers.CategoryEncoding(2, output_mode=\"one_hot\")\n",
        "\n",
        "# This is what I wanted, as it reduces the memory bandwidth required to send\n",
        "# training data to the GPU\n",
        "category_encoding_model = keras.Sequential(\n",
        "    [\n",
        "        keras.layers.Input(tf.TensorShape((1,)), dtype=tf.uint8),\n",
        "        category_encoding,\n",
        "    ]\n",
        ")\n",
        "category_encoding_model.summary()\n",
        "print(\n",
        "    f\"Category encoding model input dtype: {repr(category_encoding_model.input_dtype)}\"\n",
        ")\n",
        "\n",
        "try:\n",
        "    category_encoding_model.predict(ds)\n",
        "except TypeError as e:\n",
        "    print(f\"Could not predict with uint8 dataset: {e}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Baring that I can try to use it in the tf.data API instead.\n",
        "try:\n",
        "    ds.map(category_encoding)\n",
        "except TypeError as e:\n",
        "    print(f\"Could not map dataset: {e}\")\n",
        "\n",
        "print()\n",
        "\n",
        "# Lets try to reproduce this out of keras\n",
        "@tf.function\n",
        "def simple_one_hot(indices: tf.Tensor, depth: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Just 1-hot encode the input indices symbolicly\"\"\"\n",
        "\n",
        "    assert tf.is_symbolic_tensor(indices)\n",
        "    return tf.one_hot(indices, depth)\n",
        "\n",
        "\n",
        "nokeras_encoded = simple_one_hot(ds_tensor, tf.constant(2, dtype=tf.int32))\n",
        "print(f\"Symbolicly encoded categories using tf.one_hot: {repr(nokeras_encoded)}\")\n",
        "# Looks like it's a keras bug, or something more complex is happening behind the\n",
        "# scenes of CategoryEncoding\n",
        "\n",
        "\n",
        "# Lets try to narrow that down:\n",
        "@tf.function\n",
        "def keras_one_hot(indices: tf.Tensor, depth: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Just 1-hot encode the input indices symbolicly, but using the keras tensorflow backend\"\"\"\n",
        "\n",
        "    backend = category_encoding.backend\n",
        "    return backend.nn.one_hot(indices, depth)\n",
        "\n",
        "\n",
        "kerasnn_encoded = keras_one_hot(ds_tensor, tf.constant(2, dtype=tf.int32))\n",
        "print(\n",
        "    f\"Symbolicly encoded categories using keras backend one_hot: {repr(kerasnn_encoded)}\"\n",
        ")\n",
        "\n",
        "\n",
        "# Maybe the problem is here:\n",
        "# https://github.com/keras-team/keras/blob/f77b020/keras/layers/preprocessing/tf_data_layer.py#L30\n",
        "@tf.function\n",
        "def map_structure(inputs: tf.Tensor) -> any:\n",
        "    \"\"\"Recreate the map structure call in TFDataLayer\"\"\"\n",
        "\n",
        "    backend = category_encoding.backend\n",
        "    return keras.tree.map_structure(\n",
        "        lambda x: backend.convert_to_tensor(x, dtype=category_encoding.compute_dtype),\n",
        "        inputs,\n",
        "    )\n",
        "\n",
        "\n",
        "print(f\"CategoryEncoding compute dtype: {repr(category_encoding.compute_dtype)}\")\n",
        "mapped_indices = map_structure(ds_tensor)\n",
        "print(f\"keras.utils.tree.map_structure with converted dtype: {repr(mapped_indices)}\")\n",
        "# Looks like thats it—the compute_dtype property is the _output dtype_—which is often the input\n",
        "# dtype ... but not for CategoryEncoding.\n",
        "\n",
        "# Why does the behavior differ when executing eagerly though? 🤔\n",
        "# Because of this condition:\n",
        "# https://github.com/keras-team/keras/blob/f77b020/keras/layers/preprocessing/tf_data_layer.py#L23\n",
        "eager_encoded = category_encoding(ds_tensor)\n",
        "print(f\"Eagerly encoded categories: {repr(eager_encoded)}\")"
      ]
    }
  ]
}